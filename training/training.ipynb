{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GENERATIVE LSTM FOR NICKNAME GENERATION"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### READ AND PREPROCESS DATA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dota_names.csv\", header=None, encoding= 'Windows-1251')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   0\n0                 ele 15avg nabivayu\n1                            kitamef\n2        burythatbodyitbloodyougotit\n3                     АКАШИ СЕЙДЖУРО\n4                   АК 47 МАСТЕР 666\n...                              ...\n1959193                       Mookki\n1959194                      Boombl4\n1959195         (жмых) KIng_ak47-Awp\n1959196              hyiloebanoe1111\n1959197                      Neekeri\n\n[1959198 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ele 15avg nabivayu</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>kitamef</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>burythatbodyitbloodyougotit</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>АКАШИ СЕЙДЖУРО</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>АК 47 МАСТЕР 666</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1959193</th>\n      <td>Mookki</td>\n    </tr>\n    <tr>\n      <th>1959194</th>\n      <td>Boombl4</td>\n    </tr>\n    <tr>\n      <th>1959195</th>\n      <td>(жмых) KIng_ak47-Awp</td>\n    </tr>\n    <tr>\n      <th>1959196</th>\n      <td>hyiloebanoe1111</td>\n    </tr>\n    <tr>\n      <th>1959197</th>\n      <td>Neekeri</td>\n    </tr>\n  </tbody>\n</table>\n<p>1959198 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "digits = \"1234567890\"\n",
    "cyrillic_letters = u\"абвгдеёжзийклмнопрстуфхцчшщъыьэюя\"\n",
    "allowed_special = \".-_()? \"\n",
    "\n",
    "allowed_chars = cyrillic_letters + digits + allowed_special\n",
    "\n",
    "def strip(text):\n",
    "    text = text.lower()\n",
    "    if any([text.count(c)>10 for c in allowed_chars]):\n",
    "        return \"\"\n",
    "    text = \"\".join([c for c in text if c in allowed_chars])\n",
    "    if all(c in digits or c in allowed_special for c in text):\n",
    "        return \"\"\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/1959198 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50dab4f941f24cf3a7a4bb7848979579"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import swifter\n",
    "df[0] = df[0].astype(str).swifter.apply(strip)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "df[0] = df[0].replace(\"\", np.nan)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "df = df.dropna().drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Pandas Apply:   0%|          | 0/189090 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff44cdd4d98144198a7c41e55231a953"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[0] = df[0].astype(str).swifter.apply(lambda x: list(x))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                        0\n3              [а, к, а, ш, и,  , с, е, й, д, ж, у, р, о]\n4        [а, к,  , 4, 7,  , м, а, с, т, е, р,  , 6, 6, 6]\n5                             [а, м,  , а,  , п, у, м, а]\n6           [а, н, а, л, ь, н, ы, й,  , м, у, д, р, е, ц]\n7                             [а, л, е,  , б, а, р, н, и]\n...                                                   ...\n1959147                                   [_, н, е, г, р]\n1959154                                [п, р, а, й, м, ?]\n1959155                                [м, о, б, ш, и, д]\n1959164                          [ф, в, ы, ф, ы, ф, в, ы]\n1959170        [я,  , е, б, у,  , к, а, б, л, у, к, о, в]\n\n[189090 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>[а, к, а, ш, и,  , с, е, й, д, ж, у, р, о]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[а, к,  , 4, 7,  , м, а, с, т, е, р,  , 6, 6, 6]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[а, м,  , а,  , п, у, м, а]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[а, н, а, л, ь, н, ы, й,  , м, у, д, р, е, ц]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[а, л, е,  , б, а, р, н, и]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1959147</th>\n      <td>[_, н, е, г, р]</td>\n    </tr>\n    <tr>\n      <th>1959154</th>\n      <td>[п, р, а, й, м, ?]</td>\n    </tr>\n    <tr>\n      <th>1959155</th>\n      <td>[м, о, б, ш, и, д]</td>\n    </tr>\n    <tr>\n      <th>1959164</th>\n      <td>[ф, в, ы, ф, ы, ф, в, ы]</td>\n    </tr>\n    <tr>\n      <th>1959170</th>\n      <td>[я,  , е, б, у,  , к, а, б, л, у, к, о, в]</td>\n    </tr>\n  </tbody>\n</table>\n<p>189090 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "eos = 0\n",
    "sos = 1\n",
    "\n",
    "char_to_int = dict((c, i+2) for i, c in enumerate(allowed_chars))\n",
    "\n",
    "n_vocab = len(allowed_chars) + 2\n",
    "\n",
    "def encode(text: list) -> list:\n",
    "    return [sos] + [char_to_int[c] for c in text] + [eos]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                         0\n3        [1, 2, 13, 2, 27, 11, 51, 20, 7, 12, 6, 9, 22,...\n4        [1, 2, 13, 51, 38, 41, 51, 15, 2, 20, 21, 7, 1...\n5                  [1, 2, 15, 51, 2, 51, 18, 22, 15, 2, 0]\n6        [1, 2, 16, 2, 14, 31, 16, 30, 12, 51, 15, 22, ...\n7                   [1, 2, 14, 7, 51, 3, 2, 19, 16, 11, 0]\n...                                                    ...\n1959147                           [1, 47, 16, 7, 5, 19, 0]\n1959154                      [1, 18, 19, 2, 12, 15, 50, 0]\n1959155                       [1, 15, 17, 3, 27, 11, 6, 0]\n1959164               [1, 23, 4, 30, 23, 30, 23, 4, 30, 0]\n1959170  [1, 34, 51, 7, 3, 22, 51, 13, 2, 3, 14, 22, 13...\n\n[189090 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>[1, 2, 13, 2, 27, 11, 51, 20, 7, 12, 6, 9, 22,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[1, 2, 13, 51, 38, 41, 51, 15, 2, 20, 21, 7, 1...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[1, 2, 15, 51, 2, 51, 18, 22, 15, 2, 0]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[1, 2, 16, 2, 14, 31, 16, 30, 12, 51, 15, 22, ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[1, 2, 14, 7, 51, 3, 2, 19, 16, 11, 0]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1959147</th>\n      <td>[1, 47, 16, 7, 5, 19, 0]</td>\n    </tr>\n    <tr>\n      <th>1959154</th>\n      <td>[1, 18, 19, 2, 12, 15, 50, 0]</td>\n    </tr>\n    <tr>\n      <th>1959155</th>\n      <td>[1, 15, 17, 3, 27, 11, 6, 0]</td>\n    </tr>\n    <tr>\n      <th>1959164</th>\n      <td>[1, 23, 4, 30, 23, 30, 23, 4, 30, 0]</td>\n    </tr>\n    <tr>\n      <th>1959170</th>\n      <td>[1, 34, 51, 7, 3, 22, 51, 13, 2, 3, 14, 22, 13...</td>\n    </tr>\n  </tbody>\n</table>\n<p>189090 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0] = df[0].apply(encode)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MODEL DEFINITION AND DATA RESHAPING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38f98484089248f78cf51f956783e77c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "seq_length = 34\n",
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "length = len(df)\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    text = row[0]\n",
    "\n",
    "    for i in range(1,len(text)):\n",
    "        seq_in = text[:i]\n",
    "        seq_out = text[i]\n",
    "        dataX.append(((33 - len(seq_in)))*[0] + seq_in)\n",
    "        dataY.append(seq_out)\n",
    "n_patterns = len(dataX)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "X = torch.tensor(dataX, dtype=torch.float).reshape(n_patterns, seq_length - 1, 1)\n",
    "y = torch.tensor(dataY)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class CharModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=512, num_layers=4, batch_first=True, dropout=0.3, bias=False)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(512, n_vocab)\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.normalize(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        # take only the last output\n",
    "        x = x[:, -1, :]\n",
    "        # produce output\n",
    "        x = self.linear(self.dropout(x))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MODEL TRAINING"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "CharModel(\n  (lstm): LSTM(1, 512, num_layers=4, bias=False, batch_first=True, dropout=0.3)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=512, out_features=52, bias=True)\n)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 75\n",
    "batch_size = 3000\n",
    "model = CharModel()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, eta_min=0.0001, T_max=120)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "\n",
    "precentage = 0.1\n",
    "size = len(X)\n",
    "split = int(size*(1 - 0.1))\n",
    "\n",
    "\n",
    "X_train, y_train = X[:split], y[:split]\n",
    "X_test, y_test = X[split:], y[split:]\n",
    "\n",
    "train_loader = data.DataLoader(data.TensorDataset(X_train, y_train), shuffle=True, batch_size=batch_size)\n",
    "test_loader = data.DataLoader(data.TensorDataset(X_test, y_test), shuffle=True, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_loss = np.inf\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in tqdm(train_loader):\n",
    "        y_pred = model(X_batch.to(device))\n",
    "        loss = loss_fn(y_pred, y_batch.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            y_pred = model(X_batch.to(device))\n",
    "            loss += loss_fn(y_pred, y_batch.to(device))\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_model = model.state_dict()\n",
    "        print(\"Epoch %d: Cross-entropy: %.4f\" % (epoch, loss))\n",
    "\n",
    "torch.save([best_model, char_to_int], \"v3.pth\")\n",
    "torch.save([model.state_dict(), char_to_int], \"v3_latest.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "CharModel(\n  (lstm): LSTM(1, 512, num_layers=4, bias=False, batch_first=True, dropout=0.3)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=512, out_features=52, bias=True)\n)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generation using the trained model\n",
    "best_model, char_to_int = torch.load(\"v3.pth\")\n",
    "n_vocab = len(char_to_int)\n",
    "int_to_char = dict((i, c) for c, i in char_to_int.items())\n",
    "model.load_state_dict(best_model)\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "input = \"\"\n",
    "def encode_prompt(text: list) -> torch.tensor:\n",
    "    return torch.tensor([sos] + [char_to_int[c] for c in text], dtype=torch.float).to(device)\n",
    "\n",
    "def generate_name(prompt: str) -> str:\n",
    "\n",
    "    output = encode_prompt(list(prompt))\n",
    "    prediction = int(model(output.view(1, -1, 1)).argmax())\n",
    "\n",
    "    while prediction!=0:\n",
    "        new_char = int_to_char[prediction]\n",
    "        prompt+=new_char\n",
    "\n",
    "        output = encode_prompt(list(prompt))\n",
    "        prediction = int(model(output.view(1, -1, 1)).argmax())\n",
    "\n",
    "    return prompt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "олег барабуль\n",
      "олег барабуль\n",
      "олег барабуль\n",
      "олег барабуль\n",
      "олег барабуль\n",
      "олег барабуль\n",
      "олег барабуль\n",
      "олег барабуль\n",
      "олег барабуль\n",
      "олег барабуль\n"
     ]
    }
   ],
   "source": [
    "print(generate_name(\"ол\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "outputs": [],
   "source": [
    "def decode(encoded_name: torch.tensor) -> str:\n",
    "    result = \"\"\n",
    "    for c in encoded_name[1:]:\n",
    "        if c == 0:\n",
    "            break\n",
    "        result += int_to_char[int(c)]\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "def generate_names(prompt: str, alpha: float = 0.2, noise: bool = True, k: int = 10, split_steps: int = 5) -> str:\n",
    "    names = [encode_prompt(list(prompt))]\n",
    "    prediction0 = None\n",
    "\n",
    "    steps = 0\n",
    "\n",
    "    while prediction0!=0:\n",
    "        predictions = model(names[0].view(1, -1, 1))\n",
    "        topk = torch.topk(predictions, k)\n",
    "        prediction0 = topk.indices[0][0].reshape(1)\n",
    "        value0 = topk.values[0][0].reshape(1)\n",
    "        noise_value = 0\n",
    "\n",
    "        if steps < split_steps:\n",
    "            for i in range(1,k):\n",
    "                valuei = topk.values[0][i].reshape(1)\n",
    "                predictioni = topk.indices[0][i].reshape(1)\n",
    "\n",
    "                if noise:\n",
    "                    noise_value = torch.rand(1).to(device) / 3\n",
    "\n",
    "                if value0/valuei < 1 + alpha + noise_value:\n",
    "                    names.append(torch.cat((names[0], predictioni), 0))\n",
    "\n",
    "        names[0] = torch.cat((names[0], prediction0), 0)\n",
    "        steps+=1\n",
    "\n",
    "    for i in range(1, len(names)):\n",
    "        prediction = None\n",
    "        while prediction != 0:\n",
    "            prediction = model(names[i].view(1, -1, 1)).argmax().reshape(1)\n",
    "            names[i] = torch.cat((names[i], prediction), 0)\n",
    "\n",
    "    decoded_names = []\n",
    "    for name in names:\n",
    "        decoded_names.append(decode(name))\n",
    "    return decoded_names"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "data": {
      "text/plain": "['глобус в деле',\n 'глобул ',\n 'глобус',\n 'глобус на мать',\n 'глобус по кайфу',\n 'глобус ',\n 'глобус с пивом',\n 'глобус в попку',\n 'глобус в кашу',\n 'глобус в тапках']"
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_names(\"глобу\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### SAVE MODEL AS TORCHSCRIPT TO LOAD IN C++"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "data": {
      "text/plain": "CharModel(\n  (lstm): LSTM(1, 512, num_layers=4, bias=False, batch_first=True, dropout=0.3)\n  (dropout): Dropout(p=0.3, inplace=False)\n  (linear): Linear(in_features=512, out_features=52, bias=True)\n)"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [],
   "source": [
    "traced_script_module = torch.jit.script(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "outputs": [],
   "source": [
    "traced_script_module.save(\"1.pt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "абвгдеёжзийклмнопрстуфхцчшщъыьэюя1234567890.-_()? \n"
     ]
    }
   ],
   "source": [
    "print(allowed_chars)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: 'а', 3: 'б', 4: 'в', 5: 'г', 6: 'д', 7: 'е', 8: 'ё', 9: 'ж', 10: 'з', 11: 'и', 12: 'й', 13: 'к', 14: 'л', 15: 'м', 16: 'н', 17: 'о', 18: 'п', 19: 'р', 20: 'с', 21: 'т', 22: 'у', 23: 'ф', 24: 'х', 25: 'ц', 26: 'ч', 27: 'ш', 28: 'щ', 29: 'ъ', 30: 'ы', 31: 'ь', 32: 'э', 33: 'ю', 34: 'я', 35: '1', 36: '2', 37: '3', 38: '4', 39: '5', 40: '6', 41: '7', 42: '8', 43: '9', 44: '0', 45: '.', 46: '-', 47: '_', 48: '(', 49: ')', 50: '?', 51: ' '}\n"
     ]
    }
   ],
   "source": [
    "print(int_to_char)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([7])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_prompt(\"123123\").shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
